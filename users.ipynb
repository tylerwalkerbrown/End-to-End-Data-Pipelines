{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch_1.csv to S3.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "import db_dtypes\n",
    "import snowflake.connector\n",
    "import math\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# pip install google-cloud-bigquery google-auth pandas db-dtypes snowflake-connector-python boto3\n",
    "\n",
    "###################################\n",
    "#### NOTES ########################\n",
    "#####################################\n",
    "# NEED TO ADD IN LOGI TO MAKE A TALBE THAT HAS THE RUNTIMES OF EACH TABLE THEN THTE LAST RUN TIME WHERE YOU CHOOSE MAX FROM THE PARTICUAL TABLE THEN SAY GREATER THAN \n",
    "#### STORE THIS IN SNOWFLAKE WITH TIMESTAMPS \n",
    "#### FILTER IT IN BIG QUERY \n",
    "# CLEAR OUT THE LOCAL FILES \n",
    "\n",
    "snowflake_table = ''\n",
    "\n",
    "AWS_KEY_ID = ''\n",
    "AWS_SECRET_KEY = ''\n",
    "\n",
    "bucket = ''\n",
    "folder = 'users'\n",
    "stage_table = 'G'\n",
    "stage_table_sn = ''\n",
    "\n",
    "\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"surremor-ocf-69d6a4754b0a.json\"\n",
    "\n",
    "# ACCESS INFORMATION\n",
    "###########################################\n",
    "access_key_id =''\n",
    "secret_access_key=''\n",
    "\n",
    "\n",
    "# Set up AWS S3 client\n",
    "s3 = boto3.client('s3',\n",
    "                  aws_access_key_id='',\n",
    "                  aws_secret_access_key='',\n",
    "                  region_name='us-east-1')\n",
    "\n",
    "# Snowflake connection details\n",
    "conn = snowflake.connector.connect(\n",
    "    user='',\n",
    "    password='!',\n",
    "    account='',  # Correct format for the account parameter\n",
    "    warehouse='',\n",
    "    database='',\n",
    "    schema='',\n",
    "    role=''\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "lastrun = \"\"\"\n",
    "select MAX(TIMESTAMP) \n",
    "from GOOGLE_BIGQUERY.EVENT_VIEWS.RUNTIME_HST \n",
    "WHERE TABLE_NAME ILIKE '%GOOGLE_BIGQUERY.USERS_VIEWS.USERS_FRDV%';\n",
    "\"\"\"\n",
    "#LASTRUN = '2024-09-22'\n",
    "\n",
    "cur.execute(lastrun)\n",
    "\n",
    "\n",
    "key_path = \"bigquerykey.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "\n",
    "\n",
    "lastrun_result = cur.fetchone()  \n",
    "\n",
    "if lastrun_result and lastrun_result[0]:\n",
    "    last_run_time = lastrun_result[0].strftime('%Y-%m-%d')\n",
    "else:\n",
    "    last_run_time = None  # Handle case if there is no last run time\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  `big query data`\n",
    "\"\"\"\n",
    "df = client.query(query).to_dataframe()\n",
    "user_info_normalized = pd.json_normalize(df['user_info'])\n",
    "geo_normalized = pd.json_normalize(df['geo'])\n",
    "device_normalized = pd.json_normalize(df['device'])\n",
    "predictions_normalized = pd.json_normalize(df['predictions'])\n",
    "privacy_info_normalized = pd.json_normalize(df['privacy_info'])\n",
    "user_ltv_normalized = pd.json_normalize(df['user_ltv'])\n",
    "\n",
    "# Join the normalized DataFrames back to the original DataFrame\n",
    "# Add suffixes to columns to avoid overlap\n",
    "df_final = df.join([\n",
    "    user_info_normalized.add_suffix('_user_info'), \n",
    "    geo_normalized.add_suffix('_geo'), \n",
    "    device_normalized.add_suffix('_device'), \n",
    "    privacy_info_normalized.add_suffix('_privacy_info'),\n",
    "    predictions_normalized.add_suffix('_predictions'),\n",
    "    user_ltv_normalized.add_suffix('_user_ltv')\n",
    "\n",
    "])\n",
    "\n",
    "df_exploded = df_final.explode('audiences')\n",
    "df_exploded['name'] = df_exploded['audiences'].apply(lambda x: x['name'] if isinstance(x, dict) else None)\n",
    "df_exploded['membership_start_timestamp_micros'] = df_exploded['audiences'].apply(lambda x: x['membership_start_timestamp_micros'] if isinstance(x, dict) else None)\n",
    "df_exploded['membership_expiry_timestamp_micros'] = df_exploded['audiences'].apply(lambda x: x.get('membership_expiry_timestamp_micros') if isinstance(x, dict) else None)\n",
    "df_exploded['npa'] = df_exploded['audiences'].apply(lambda x: x.get('npa') if isinstance(x, dict) else None)\n",
    "df_exploded['id'] = df_exploded['audiences'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
    "\n",
    "\n",
    "# Drop the original nested columns if necessary\n",
    "df_final = df_final.drop(columns=['user_info', \n",
    "                                  'device', \n",
    "                                  'geo', \n",
    "                                  'predictions', \n",
    "                                  'privacy_info',\n",
    "                                  'user_ltv',\n",
    "                                  'audiences',\n",
    "                                  'user_properties'])\n",
    "df_final.columns = df_final.columns.str.replace('.', '_', regex=False)\n",
    "\n",
    "\n",
    "numeric_columns = df_final.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_final[numeric_columns] = df_final[numeric_columns].fillna(0)\n",
    "string_columns = df_final.select_dtypes(include=['object']).columns\n",
    "df_final[string_columns] = df_final[string_columns].fillna('Unknown')\n",
    "boolean_columns = df_final.select_dtypes(include=['bool']).columns\n",
    "df_final[boolean_columns] = df_final[boolean_columns].fillna(False)\n",
    "df_final.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "df_final['pseudo_user_id'] = df_final['pseudo_user_id'].astype(object)\n",
    "df_final['stream_id'] = df_final['stream_id'].astype(object)\n",
    "df_final['occurrence_date'] = df_final['occurrence_date'].astype(object)\n",
    "df_final['last_updated_date'] = df_final['last_updated_date'].astype(object)\n",
    "df_final['last_active_timestamp_micros_user_info'] = df_final['last_active_timestamp_micros_user_info'].astype(object)\n",
    "df_final['user_first_touch_timestamp_micros_user_info'] = df_final['user_first_touch_timestamp_micros_user_info'].astype(object)\n",
    "df_final['first_purchase_date_user_info'] = df_final['first_purchase_date_user_info'].astype(object)\n",
    "df_final['city_geo'] = df_final['city_geo'].astype(object)\n",
    "df_final['country_geo'] = df_final['country_geo'].astype(object)\n",
    "df_final['continent_geo'] = df_final['continent_geo'].astype(object)\n",
    "df_final['region_geo'] = df_final['region_geo'].astype(object)\n",
    "df_final['operating_system_device'] = df_final['operating_system_device'].astype(object)\n",
    "df_final['category_device'] = df_final['category_device'].astype(object)\n",
    "df_final['mobile_brand_name_device'] = df_final['mobile_brand_name_device'].astype(object)\n",
    "df_final['mobile_model_name_device'] = df_final['mobile_model_name_device'].astype(object)\n",
    "df_final['unified_screen_name_device'] = df_final['unified_screen_name_device'].astype(object)\n",
    "df_final['is_limited_ad_tracking_privacy_info'] = df_final['is_limited_ad_tracking_privacy_info'].astype(object)\n",
    "df_final['is_ads_personalization_allowed_privacy_info'] = df_final['is_ads_personalization_allowed_privacy_info'].astype(object)\n",
    "df_final['in_app_purchase_score_7d_predictions'] = df_final['in_app_purchase_score_7d_predictions'].astype(object)\n",
    "df_final['purchase_score_7d_predictions'] = df_final['purchase_score_7d_predictions'].astype(object)\n",
    "df_final['churn_score_7d_predictions'] = df_final['churn_score_7d_predictions'].astype(object)\n",
    "df_final['revenue_28d_in_usd_predictions'] = df_final['revenue_28d_in_usd_predictions'].astype(object)\n",
    "df_final['revenue_in_usd_user_ltv'] = df_final['revenue_in_usd_user_ltv'].astype(object)\n",
    "df_final['sessions_user_ltv'] = df_final['sessions_user_ltv'].astype(object)\n",
    "df_final['engagement_time_millis_user_ltv'] = df_final['engagement_time_millis_user_ltv'].astype(object)\n",
    "df_final['purchases_user_ltv'] = df_final['purchases_user_ltv'].astype(object)\n",
    "df_final['engaged_sessions_user_ltv'] = df_final['engaged_sessions_user_ltv'].astype(object)\n",
    "df_final['session_duration_micros_user_ltv'] = df_final['session_duration_micros_user_ltv'].astype(object)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 100000\n",
    "num_batches = len(df_final) // batch_size + 1\n",
    "\n",
    "# Loop through and upload batches\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = min((i + 1) * batch_size, len(df_final))\n",
    "    \n",
    "    # Slice DataFrame into a batch\n",
    "    batch_data = df_final[start_idx:end_idx]\n",
    "    \n",
    "    # Save batch to a temporary CSV file\n",
    "    file_name = f'batch_{i+1}.csv'\n",
    "    batch_data.to_csv(file_name, index=False)\n",
    "    \n",
    "    # Upload CSV to S3\n",
    "    s3.upload_file(file_name,bucket, f'{folder}/' + file_name)\n",
    "\n",
    "    print(f\"Uploaded {file_name} to S3.\")\n",
    "\n",
    "# Load data from S3 into Snowflake table\n",
    "copy_command = f\"\"\"\n",
    "COPY INTO {stage_table_sn}\n",
    "FROM 's3://{bucket}/{folder}/{file_name}'\n",
    "CREDENTIALS = (AWS_KEY_ID = '{AWS_KEY_ID}' AWS_SECRET_KEY = '{AWS_SECRET_KEY}')\n",
    "FILE_FORMAT = (\n",
    "    TYPE = 'CSV' \n",
    "    FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "    SKIP_HEADER = 1\n",
    "    ERROR_ON_COLUMN_COUNT_MISMATCH = FALSE\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(copy_command)\n",
    "\n",
    "merge = \"\"\"MERGE INTO GOOGLE_BIGQUERY.USERS_VIEWS.USERS_FRDV AS tgt\n",
    "USING GOOGLE_BIGQUERY.USERS_VIEWS.USERS_STAGE AS src\n",
    "ON tgt.pseudo_user_id = src.pseudo_user_id\n",
    "   AND tgt.stream_id = src.stream_id\n",
    "   AND tgt.occurrence_date = src.occurrence_date\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET\n",
    "        tgt.last_updated_date = src.last_updated_date,\n",
    "        tgt.last_active_timestamp_micros_user_info = src.last_active_timestamp_micros_user_info,\n",
    "        tgt.user_first_touch_timestamp_micros_user_info = src.user_first_touch_timestamp_micros_user_info,\n",
    "        tgt.first_purchase_date_user_info = src.first_purchase_date_user_info,\n",
    "        tgt.city_geo = src.city_geo,\n",
    "        tgt.country_geo = src.country_geo,\n",
    "        tgt.continent_geo = src.continent_geo,\n",
    "        tgt.region_geo = src.region_geo,\n",
    "        tgt.operating_system_device = src.operating_system_device,\n",
    "        tgt.category_device = src.category_device,\n",
    "        tgt.mobile_brand_name_device = src.mobile_brand_name_device,\n",
    "        tgt.mobile_model_name_device = src.mobile_model_name_device,\n",
    "        tgt.unified_screen_name_device = src.unified_screen_name_device,\n",
    "        tgt.is_limited_ad_tracking_privacy_info = src.is_limited_ad_tracking_privacy_info,\n",
    "        tgt.is_ads_personalization_allowed_privacy_info = src.is_ads_personalization_allowed_privacy_info,\n",
    "        tgt.in_app_purchase_score_7d_predictions = src.in_app_purchase_score_7d_predictions,\n",
    "        tgt.purchase_score_7d_predictions = src.purchase_score_7d_predictions,\n",
    "        tgt.churn_score_7d_predictions = src.churn_score_7d_predictions,\n",
    "        tgt.revenue_28d_in_usd_predictions = src.revenue_28d_in_usd_predictions,\n",
    "        tgt.revenue_in_usd_user_ltv = src.revenue_in_usd_user_ltv,\n",
    "        tgt.sessions_user_ltv = src.sessions_user_ltv,\n",
    "        tgt.engagement_time_millis_user_ltv = src.engagement_time_millis_user_ltv,\n",
    "        tgt.purchases_user_ltv = src.purchases_user_ltv,\n",
    "        tgt.engaged_sessions_user_ltv = src.engaged_sessions_user_ltv,\n",
    "        tgt.session_duration_micros_user_ltv = src.session_duration_micros_user_ltv\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (\n",
    "        pseudo_user_id,\n",
    "        stream_id,\n",
    "        occurrence_date,\n",
    "        last_updated_date,\n",
    "        last_active_timestamp_micros_user_info,\n",
    "        user_first_touch_timestamp_micros_user_info,\n",
    "        first_purchase_date_user_info,\n",
    "        city_geo,\n",
    "        country_geo,\n",
    "        continent_geo,\n",
    "        region_geo,\n",
    "        operating_system_device,\n",
    "        category_device,\n",
    "        mobile_brand_name_device,\n",
    "        mobile_model_name_device,\n",
    "        unified_screen_name_device,\n",
    "        is_limited_ad_tracking_privacy_info,\n",
    "        is_ads_personalization_allowed_privacy_info,\n",
    "        in_app_purchase_score_7d_predictions,\n",
    "        purchase_score_7d_predictions,\n",
    "        churn_score_7d_predictions,\n",
    "        revenue_28d_in_usd_predictions,\n",
    "        revenue_in_usd_user_ltv,\n",
    "        sessions_user_ltv,\n",
    "        engagement_time_millis_user_ltv,\n",
    "        purchases_user_ltv,\n",
    "        engaged_sessions_user_ltv,\n",
    "        session_duration_micros_user_ltv\n",
    "    )\n",
    "    VALUES (\n",
    "        src.pseudo_user_id,\n",
    "        src.stream_id,\n",
    "        src.occurrence_date,\n",
    "        src.last_updated_date,\n",
    "        src.last_active_timestamp_micros_user_info,\n",
    "        src.user_first_touch_timestamp_micros_user_info,\n",
    "        src.first_purchase_date_user_info,\n",
    "        src.city_geo,\n",
    "        src.country_geo,\n",
    "        src.continent_geo,\n",
    "        src.region_geo,\n",
    "        src.operating_system_device,\n",
    "        src.category_device,\n",
    "        src.mobile_brand_name_device,\n",
    "        src.mobile_model_name_device,\n",
    "        src.unified_screen_name_device,\n",
    "        src.is_limited_ad_tracking_privacy_info,\n",
    "        src.is_ads_personalization_allowed_privacy_info,\n",
    "        src.in_app_purchase_score_7d_predictions,\n",
    "        src.purchase_score_7d_predictions,\n",
    "        src.churn_score_7d_predictions,\n",
    "        src.revenue_28d_in_usd_predictions,\n",
    "        src.revenue_in_usd_user_ltv,\n",
    "        src.sessions_user_ltv,\n",
    "        src.engagement_time_millis_user_ltv,\n",
    "        src.purchases_user_ltv,\n",
    "        src.engaged_sessions_user_ltv,\n",
    "        src.session_duration_micros_user_ltv\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(merge)\n",
    "\n",
    "response = s3.list_objects_v2(Bucket= bucket , Prefix=f'{bucket}/{folder}/')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
